#!/bin/bash
# Script tá»± Ä‘á»™ng setup GKE cluster cho teammate
# Cháº¡y trÃªn Ubuntu WSL

set -e

echo "ğŸš€ BIG DATA PIPELINE - GKE SETUP SCRIPT"
echo "========================================"

# YÃªu cáº§u nháº­p thÃ´ng tin
read -p "Nháº­p tÃªn cá»§a báº¡n (vÃ­ dá»¥: tung, dat): " USER_NAME
read -p "Nháº­p Project ID (vÃ­ dá»¥: my-bigdata-123): " PROJECT_ID
read -p "Nháº­p Region (máº·c Ä‘á»‹nh: asia-northeast1): " REGION
REGION=${REGION:-asia-northeast1}

CLUSTER_NAME="${USER_NAME}-cluster"
ZONE="${REGION}-c"

echo ""
echo "ğŸ“‹ ThÃ´ng tin setup:"
echo "  - Cluster name: $CLUSTER_NAME"
echo "  - Project ID: $PROJECT_ID"
echo "  - Zone: $ZONE"
echo ""
read -p "XÃ¡c nháº­n? (y/n): " CONFIRM

if [ "$CONFIRM" != "y" ]; then
    echo "Há»§y bá»."
    exit 1
fi

# 1. Set project
echo "ğŸ”§ Setting project..."
gcloud config set project $PROJECT_ID

# 2. Enable APIs
echo "ğŸ”§ Enabling required APIs..."
gcloud services enable container.googleapis.com
gcloud services enable artifactregistry.googleapis.com
gcloud services enable cloudbuild.googleapis.com

# 3. Táº¡o cluster
echo "ğŸ—ï¸ Creating GKE cluster (máº¥t khoáº£ng 5-10 phÃºt)..."
gcloud container clusters create $CLUSTER_NAME \
  --zone $ZONE \
  --num-nodes 3 \
  --machine-type e2-standard-4 \
  --disk-size 50 \
  --enable-autoscaling \
  --min-nodes 1 \
  --max-nodes 5 \
  --enable-autorepair \
  --enable-autoupgrade

# 4. Get credentials
echo "ğŸ”‘ Getting cluster credentials..."
gcloud container clusters get-credentials $CLUSTER_NAME \
  --zone $ZONE \
  --project $PROJECT_ID

# 5. Verify
echo "âœ… Kiá»ƒm tra káº¿t ná»‘i..."
kubectl config current-context
kubectl get nodes

# 6. Táº¡o namespaces
echo "ğŸ“¦ Táº¡o namespaces..."
kubectl create namespace kafka || true
kubectl create namespace big-data-pipeline || true

# 7. Install Strimzi Operator
echo "ğŸ“¦ CÃ i Ä‘áº·t Strimzi Operator cho Kafka..."
kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka

# 8. Táº¡o Artifact Registry
echo "ğŸ“¦ Táº¡o Artifact Registry..."
gcloud artifacts repositories create my-repo \
  --repository-format=docker \
  --location=$REGION \
  --description="Docker repository for Big Data Pipeline" || true

echo ""
echo "âœ… ======================================"
echo "âœ… SETUP HOÃ€N Táº¤T!"
echo "âœ… ======================================"
echo ""
echo "ğŸ“‹ ThÃ´ng tin cluster cá»§a báº¡n:"
echo "  - Cluster: $CLUSTER_NAME"
echo "  - Zone: $ZONE"
echo "  - Project: $PROJECT_ID"
echo ""
echo "ğŸ¯ BÆ°á»›c tiáº¿p theo:"
echo "  1. Cháº¡y: kubectl get nodes"
echo "  2. Deploy Kafka: kubectl apply -f kafka-kraft.yaml"
echo "  3. Xem hÆ°á»›ng dáº«n chi tiáº¿t trong: DEPLOY_GUIDE_GKE.md"
echo ""
echo "ğŸ’¡ LÆ°u Ã½:"
echo "  - Cluster Ä‘ang cháº¡y sáº½ tá»‘n phÃ­ (~$3-5/ngÃ y)"
echo "  - Khi test xong, cháº¡y: gcloud container clusters delete $CLUSTER_NAME --zone $ZONE"
echo ""
